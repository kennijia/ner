2020-12-01 13:33:03,261:INFO: device: cuda:1
2020-12-01 13:33:03,261:INFO: --------Process Done!--------
2020-12-01 13:33:03,424:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2020-12-01 13:33:03,424:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2020-12-01 13:33:03,424:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2020-12-01 13:33:03,424:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2020-12-01 13:33:03,424:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2020-12-01 13:33:03,424:INFO: loading file None
2020-12-01 13:33:03,424:INFO: loading file None
2020-12-01 13:33:03,424:INFO: loading file None
2020-12-01 13:33:16,782:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2020-12-01 13:33:16,782:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2020-12-01 13:33:16,782:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2020-12-01 13:33:16,782:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2020-12-01 13:33:16,782:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2020-12-01 13:33:16,782:INFO: loading file None
2020-12-01 13:33:16,782:INFO: loading file None
2020-12-01 13:33:16,782:INFO: loading file None
2020-12-01 13:33:18,266:INFO: --------Dataset Build!--------
2020-12-01 13:33:18,266:INFO: --------Get Dataloader!--------
2020-12-01 13:33:18,266:INFO: loading configuration file pretrained_bert_models/chinese_roberta_wwm_large_ext/config.json
2020-12-01 13:33:18,266:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 31,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 21128
}

2020-12-01 13:33:18,267:INFO: loading weights file pretrained_bert_models/chinese_roberta_wwm_large_ext/pytorch_model.bin
2020-12-01 13:33:25,525:INFO: Weights of BertNER not initialized from pretrained model: ['classifier.weight', 'classifier.bias', 'crf.start_transitions', 'crf.end_transitions', 'crf.transitions']
2020-12-01 13:33:25,525:INFO: Weights from pretrained model not used in BertNER: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
2020-12-01 13:33:27,356:INFO: --------Start Training!--------
2020-12-01 13:36:31,717:INFO: Epoch: 1, train loss: 951.2736621642664
2020-12-01 13:36:43,331:INFO: Epoch: 1, dev loss: 279.6296974630917, f1 score: 0.6818967172201958
2020-12-01 13:36:43,331:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 13:36:46,321:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 13:36:46,321:INFO: --------Save best model!--------
2020-12-01 13:39:52,203:INFO: Epoch: 2, train loss: 228.03223801918156
2020-12-01 13:40:03,820:INFO: Epoch: 2, dev loss: 239.37650680541992, f1 score: 0.7294252434599962
2020-12-01 13:40:03,820:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 13:40:06,631:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 13:40:06,631:INFO: --------Save best model!--------
2020-12-01 13:43:12,478:INFO: Epoch: 3, train loss: 164.66184861589187
2020-12-01 13:43:24,193:INFO: Epoch: 3, dev loss: 252.63656257180605, f1 score: 0.7525464349910125
2020-12-01 13:43:24,193:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 13:43:27,205:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 13:43:27,205:INFO: --------Save best model!--------
2020-12-01 13:46:32,996:INFO: Epoch: 4, train loss: 118.39172640255968
2020-12-01 13:46:44,658:INFO: Epoch: 4, dev loss: 258.1762426039752, f1 score: 0.7524907208439148
2020-12-01 13:49:50,431:INFO: Epoch: 5, train loss: 84.13382827960226
2020-12-01 13:50:02,088:INFO: Epoch: 5, dev loss: 306.5032804152545, f1 score: 0.7637028014616322
2020-12-01 13:50:02,089:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 13:50:04,913:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 13:50:04,914:INFO: --------Save best model!--------
2020-12-01 13:53:10,746:INFO: Epoch: 6, train loss: 65.19358886743929
2020-12-01 13:53:22,423:INFO: Epoch: 6, dev loss: 310.6508869844324, f1 score: 0.7609046849757672
2020-12-01 13:56:28,171:INFO: Epoch: 7, train loss: 48.097676809078
2020-12-01 13:56:39,836:INFO: Epoch: 7, dev loss: 340.42704413918887, f1 score: 0.7683224755700325
2020-12-01 13:56:39,836:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 13:56:42,496:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 13:56:42,496:INFO: --------Save best model!--------
2020-12-01 13:59:48,276:INFO: Epoch: 8, train loss: 37.92243501770221
2020-12-01 13:59:59,979:INFO: Epoch: 8, dev loss: 362.5531355913948, f1 score: 0.7734422880490295
2020-12-01 13:59:59,980:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 14:00:01,947:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 14:00:01,948:INFO: --------Save best model!--------
2020-12-01 14:03:07,768:INFO: Epoch: 9, train loss: 26.867554522977017
2020-12-01 14:03:19,527:INFO: Epoch: 9, dev loss: 392.8717862297507, f1 score: 0.7718800648298217
2020-12-01 14:06:25,378:INFO: Epoch: 10, train loss: 25.02924417426484
2020-12-01 14:06:37,072:INFO: Epoch: 10, dev loss: 412.19294963163486, f1 score: 0.7778003659280341
2020-12-01 14:06:37,072:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 14:06:39,189:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 14:06:39,190:INFO: --------Save best model!--------
2020-12-01 14:09:45,079:INFO: Epoch: 11, train loss: 19.092204090785664
2020-12-01 14:09:56,757:INFO: Epoch: 11, dev loss: 440.2259871538948, f1 score: 0.7807637906647807
2020-12-01 14:09:56,757:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 14:09:59,281:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 14:09:59,281:INFO: --------Save best model!--------
2020-12-01 14:13:05,177:INFO: Epoch: 12, train loss: 17.603890900564664
2020-12-01 14:13:16,966:INFO: Epoch: 12, dev loss: 467.6682227639591, f1 score: 0.7699856879983643
2020-12-01 14:16:22,809:INFO: Epoch: 13, train loss: 14.455676377803185
2020-12-01 14:16:34,576:INFO: Epoch: 13, dev loss: 481.09236593807447, f1 score: 0.7745549109821964
2020-12-01 14:19:40,449:INFO: Epoch: 14, train loss: 13.503815496715381
2020-12-01 14:19:52,145:INFO: Epoch: 14, dev loss: 557.4899920295267, f1 score: 0.7767658368751265
2020-12-01 14:22:57,886:INFO: Epoch: 15, train loss: 14.316994330277144
2020-12-01 14:23:09,592:INFO: Epoch: 15, dev loss: 547.4151907528149, f1 score: 0.7723250201126308
2020-12-01 14:26:15,341:INFO: Epoch: 16, train loss: 13.024736234457185
2020-12-01 14:26:27,058:INFO: Epoch: 16, dev loss: 573.4912154253791, f1 score: 0.7720986169573061
2020-12-01 14:29:32,960:INFO: Epoch: 17, train loss: 14.048635973788723
2020-12-01 14:29:44,685:INFO: Epoch: 17, dev loss: 601.0456300623276, f1 score: 0.7760649087221096
2020-12-01 14:32:50,568:INFO: Epoch: 18, train loss: 10.434598733883092
2020-12-01 14:33:02,267:INFO: Epoch: 18, dev loss: 647.2506112491383, f1 score: 0.7806464728603375
2020-12-01 14:36:08,034:INFO: Epoch: 19, train loss: 9.375954152727285
2020-12-01 14:36:19,727:INFO: Epoch: 19, dev loss: 666.4878414378446, f1 score: 0.7838441242135175
2020-12-01 14:36:19,727:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 14:36:22,722:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 14:36:22,722:INFO: --------Save best model!--------
2020-12-01 14:39:28,563:INFO: Epoch: 20, train loss: 10.752163367696328
2020-12-01 14:39:40,227:INFO: Epoch: 20, dev loss: 649.8650171616498, f1 score: 0.7875584468387883
2020-12-01 14:39:40,227:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 14:39:43,056:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 14:39:43,057:INFO: --------Save best model!--------
2020-12-01 14:42:48,814:INFO: Epoch: 21, train loss: 8.023733988846883
2020-12-01 14:43:00,510:INFO: Epoch: 21, dev loss: 709.5828857421875, f1 score: 0.7857720291026677
2020-12-01 14:46:06,252:INFO: Epoch: 22, train loss: 7.294849477585393
2020-12-01 14:46:17,964:INFO: Epoch: 22, dev loss: 695.2780169318704, f1 score: 0.7765656565656566
2020-12-01 14:49:23,822:INFO: Epoch: 23, train loss: 7.566181478720687
2020-12-01 14:49:35,584:INFO: Epoch: 23, dev loss: 719.2264565860523, f1 score: 0.7838283828382838
2020-12-01 14:52:41,325:INFO: Epoch: 24, train loss: 7.22852365097197
2020-12-01 14:52:53,021:INFO: Epoch: 24, dev loss: 778.3901609532974, f1 score: 0.7828210869122736
2020-12-01 14:55:58,804:INFO: Epoch: 25, train loss: 6.50024410285572
2020-12-01 14:56:10,658:INFO: Epoch: 25, dev loss: 737.0790333467371, f1 score: 0.7857576370625126
2020-12-01 14:59:16,207:INFO: Epoch: 26, train loss: 4.421250972810752
2020-12-01 14:59:27,914:INFO: Epoch: 26, dev loss: 722.8304981904871, f1 score: 0.7904781448799508
2020-12-01 14:59:27,914:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 14:59:30,773:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 14:59:30,773:INFO: --------Save best model!--------
2020-12-01 15:02:35,692:INFO: Epoch: 27, train loss: 3.737609607551751
2020-12-01 15:02:47,413:INFO: Epoch: 27, dev loss: 768.0309645708869, f1 score: 0.7929838874158679
2020-12-01 15:02:47,413:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 15:02:49,590:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 15:02:49,590:INFO: --------Save best model!--------
2020-12-01 15:05:55,215:INFO: Epoch: 28, train loss: 3.3573529720306396
2020-12-01 15:06:06,996:INFO: Epoch: 28, dev loss: 761.2072726978976, f1 score: 0.7882496940024479
2020-12-01 15:09:12,609:INFO: Epoch: 29, train loss: 2.9233443898336327
2020-12-01 15:09:24,303:INFO: Epoch: 29, dev loss: 768.9662201825311, f1 score: 0.7922369765066394
2020-12-01 15:12:29,514:INFO: Epoch: 30, train loss: 2.781141443221089
2020-12-01 15:12:41,174:INFO: Epoch: 30, dev loss: 816.4055005241843, f1 score: 0.7818070067609098
2020-12-01 15:15:46,071:INFO: Epoch: 31, train loss: 2.7729429616393038
2020-12-01 15:15:57,948:INFO: Epoch: 31, dev loss: 799.303887759938, f1 score: 0.7934358974358975
2020-12-01 15:15:57,949:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 15:16:00,580:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 15:16:00,580:INFO: --------Save best model!--------
2020-12-01 15:19:05,515:INFO: Epoch: 32, train loss: 2.1008847184700543
2020-12-01 15:19:17,182:INFO: Epoch: 32, dev loss: 819.6164514878217, f1 score: 0.7883360522022839
2020-12-01 15:22:22,737:INFO: Epoch: 33, train loss: 1.604712951694778
2020-12-01 15:22:34,464:INFO: Epoch: 33, dev loss: 773.4332463881549, f1 score: 0.7908590083656396
2020-12-01 15:25:40,003:INFO: Epoch: 34, train loss: 1.5516732569181486
2020-12-01 15:25:51,674:INFO: Epoch: 34, dev loss: 741.5038120045382, f1 score: 0.7925370107483269
2020-12-01 15:28:57,459:INFO: Epoch: 35, train loss: 0.7935247614045348
2020-12-01 15:29:09,113:INFO: Epoch: 35, dev loss: 723.020263671875, f1 score: 0.7916666666666666
2020-12-01 15:32:14,883:INFO: Epoch: 36, train loss: 1.0356213094377675
2020-12-01 15:32:26,688:INFO: Epoch: 36, dev loss: 671.5889919505399, f1 score: 0.7934253246753247
2020-12-01 15:35:32,511:INFO: Epoch: 37, train loss: 0.8806796309971573
2020-12-01 15:35:44,282:INFO: Epoch: 37, dev loss: 644.9647221284754, f1 score: 0.7963265306122449
2020-12-01 15:35:44,282:INFO: Configuration saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 15:35:46,408:INFO: Model weights saved in /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 15:35:46,408:INFO: --------Save best model!--------
2020-12-01 15:38:52,184:INFO: Epoch: 38, train loss: 0.8647545037096483
2020-12-01 15:39:03,965:INFO: Epoch: 38, dev loss: 642.024518181296, f1 score: 0.7962586417242781
2020-12-01 15:42:09,843:INFO: Epoch: 39, train loss: 0.6671175940988874
2020-12-01 15:42:21,551:INFO: Epoch: 39, dev loss: 646.3970830580768, f1 score: 0.788801976121861
2020-12-01 15:45:27,274:INFO: Epoch: 40, train loss: 0.3546022220019854
2020-12-01 15:45:39,022:INFO: Epoch: 40, dev loss: 634.860793169807, f1 score: 0.7917263977063281
2020-12-01 15:48:44,927:INFO: Epoch: 41, train loss: 0.6181547460776351
2020-12-01 15:48:56,625:INFO: Epoch: 41, dev loss: 637.3542767693015, f1 score: 0.7933647347941839
2020-12-01 15:52:02,372:INFO: Epoch: 42, train loss: 0.6576380462142895
2020-12-01 15:52:14,099:INFO: Epoch: 42, dev loss: 620.6429290771484, f1 score: 0.7934426229508196
2020-12-01 15:55:19,556:INFO: Epoch: 43, train loss: 0.38948132102638977
2020-12-01 15:55:31,258:INFO: Epoch: 43, dev loss: 617.4739137537339, f1 score: 0.7932869422840769
2020-12-01 15:58:36,985:INFO: Epoch: 44, train loss: 0.41563916599789863
2020-12-01 15:58:48,680:INFO: Epoch: 44, dev loss: 625.391580918256, f1 score: 0.7914285714285715
2020-12-01 16:01:54,441:INFO: Epoch: 45, train loss: 0.43598857413817554
2020-12-01 16:02:06,124:INFO: Epoch: 45, dev loss: 620.3849523207721, f1 score: 0.7912670883493164
2020-12-01 16:05:11,876:INFO: Epoch: 46, train loss: 0.4514781335006059
2020-12-01 16:05:23,634:INFO: Epoch: 46, dev loss: 621.4357506247128, f1 score: 0.7937997144605344
2020-12-01 16:08:29,512:INFO: Epoch: 47, train loss: 0.43516185496113086
2020-12-01 16:08:41,211:INFO: Epoch: 47, dev loss: 621.5245433134191, f1 score: 0.7937091503267976
2020-12-01 16:08:41,211:INFO: Best val f1: 0.7963265306122449
2020-12-01 16:08:41,211:INFO: Training Finished!
2020-12-01 16:08:41,247:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2020-12-01 16:08:41,247:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2020-12-01 16:08:41,247:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2020-12-01 16:08:41,247:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2020-12-01 16:08:41,248:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2020-12-01 16:08:41,248:INFO: loading file None
2020-12-01 16:08:41,248:INFO: loading file None
2020-12-01 16:08:41,248:INFO: loading file None
2020-12-01 16:08:43,084:INFO: --------Dataset Build!--------
2020-12-01 16:08:43,085:INFO: --------Get Data-loader!--------
2020-12-01 16:08:43,090:INFO: loading configuration file /home/xiaheming/workspace/BERT-NER/experiments/clue/config.json
2020-12-01 16:08:43,090:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 31,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 21128
}

2020-12-01 16:08:43,091:INFO: loading weights file /home/xiaheming/workspace/BERT-NER/experiments/clue/pytorch_model.bin
2020-12-01 16:08:49,960:INFO: --------Load model from /home/xiaheming/workspace/BERT-NER/experiments/clue/--------
2020-12-01 16:08:49,961:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2020-12-01 16:08:49,961:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2020-12-01 16:08:49,961:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2020-12-01 16:08:49,961:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2020-12-01 16:08:49,961:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2020-12-01 16:08:49,961:INFO: loading file None
2020-12-01 16:08:49,961:INFO: loading file None
2020-12-01 16:08:49,961:INFO: loading file None
2020-12-01 16:09:06,320:INFO: --------Bad Cases reserved !--------
2020-12-01 16:09:06,393:INFO: test loss: 642.8179375784738, f1 score: 0.7934279789440102
2020-12-01 16:09:06,393:INFO: f1 score of address: 0.6410596026490066
2020-12-01 16:09:06,394:INFO: f1 score of book: 0.8093645484949833
2020-12-01 16:09:06,394:INFO: f1 score of company: 0.8010403120936281
2020-12-01 16:09:06,394:INFO: f1 score of game: 0.8373590982286634
2020-12-01 16:09:06,394:INFO: f1 score of government: 0.8313725490196079
2020-12-01 16:09:06,394:INFO: f1 score of movie: 0.8310810810810811
2020-12-01 16:09:06,394:INFO: f1 score of name: 0.8743509865005192
2020-12-01 16:09:06,394:INFO: f1 score of organization: 0.8032345013477089
2020-12-01 16:09:06,394:INFO: f1 score of position: 0.7894736842105263
2020-12-01 16:09:06,394:INFO: f1 score of scene: 0.7136363636363637
2025-12-23 18:10:03,129:INFO: device: cuda:0
2025-12-23 18:10:03,129:INFO: --------Process Done!--------
2025-12-23 18:10:03,311:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-23 18:10:03,311:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/vocab.txt. We won't load it.
2025-12-23 18:10:03,311:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-23 18:10:03,311:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-23 18:10:03,311:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 15:42:08,927:INFO: device: cuda:0
2025-12-24 15:42:08,928:INFO: --------Process Done!--------
2025-12-24 15:42:09,114:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-24 15:42:09,115:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-24 15:42:09,115:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-24 15:42:09,115:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 15:42:09,115:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2025-12-24 15:42:09,115:INFO: loading file None
2025-12-24 15:42:09,115:INFO: loading file None
2025-12-24 15:42:09,115:INFO: loading file None
2025-12-24 15:42:20,856:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-24 15:42:20,856:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-24 15:42:20,856:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-24 15:42:20,856:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 15:42:20,856:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2025-12-24 15:42:20,856:INFO: loading file None
2025-12-24 15:42:20,856:INFO: loading file None
2025-12-24 15:42:20,856:INFO: loading file None
2025-12-24 15:42:22,144:INFO: --------Dataset Build!--------
2025-12-24 15:42:22,145:INFO: --------Get Dataloader!--------
2025-12-24 15:42:22,145:INFO: loading configuration file pretrained_bert_models/chinese_roberta_wwm_large_ext/config.json
2025-12-24 15:42:22,145:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 31,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 21128
}

2025-12-24 15:42:22,146:INFO: loading weights file pretrained_bert_models/chinese_roberta_wwm_large_ext/pytorch_model.bin
2025-12-24 15:42:29,079:INFO: Weights of BertNER not initialized from pretrained model: ['classifier.weight', 'classifier.bias', 'crf.start_transitions', 'crf.end_transitions', 'crf.transitions']
2025-12-24 15:42:29,079:INFO: Weights from pretrained model not used in BertNER: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
2025-12-24 15:42:30,881:INFO: --------Start Training!--------
2025-12-24 15:44:59,822:INFO: Epoch: 1, train loss: 83.3098480792085
2025-12-24 15:45:06,513:INFO: Epoch: 1, dev loss: 57.35309682775427, f1 score: 0.7657784011220197
2025-12-24 15:45:06,515:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 15:45:08,258:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 15:45:08,258:INFO: --------Save best model!--------
2025-12-24 15:45:08,258:INFO: Best val f1: 0.7657784011220197
2025-12-24 15:45:08,258:INFO: Training Finished!
2025-12-24 15:45:08,314:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-24 15:45:08,314:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-24 15:45:08,314:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-24 15:45:08,314:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 15:45:08,314:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2025-12-24 15:45:08,314:INFO: loading file None
2025-12-24 15:45:08,314:INFO: loading file None
2025-12-24 15:45:08,315:INFO: loading file None
2025-12-24 15:45:09,879:INFO: --------Dataset Build!--------
2025-12-24 15:45:09,880:INFO: --------Get Data-loader!--------
2025-12-24 15:45:09,880:INFO: loading configuration file /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 15:45:09,881:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 31,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 21128
}

2025-12-24 15:45:09,881:INFO: loading weights file /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 15:45:16,688:INFO: --------Load model from /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/--------
2025-12-24 15:45:16,690:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-24 15:45:16,690:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-24 15:45:16,690:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-24 15:45:16,690:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 15:45:16,690:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2025-12-24 15:45:16,690:INFO: loading file None
2025-12-24 15:45:16,690:INFO: loading file None
2025-12-24 15:45:16,690:INFO: loading file None
2025-12-24 15:51:34,281:INFO: device: cuda:0
2025-12-24 15:51:34,281:INFO: --------Process Done!--------
2025-12-24 15:51:34,473:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-24 15:51:34,473:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-24 15:51:34,473:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-24 15:51:34,473:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 15:51:34,473:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2025-12-24 15:51:34,473:INFO: loading file None
2025-12-24 15:51:34,473:INFO: loading file None
2025-12-24 15:51:34,474:INFO: loading file None
2025-12-24 15:51:46,402:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-24 15:51:46,403:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-24 15:51:46,403:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-24 15:51:46,403:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 15:51:46,403:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2025-12-24 15:51:46,403:INFO: loading file None
2025-12-24 15:51:46,403:INFO: loading file None
2025-12-24 15:51:46,403:INFO: loading file None
2025-12-24 15:51:47,689:INFO: --------Dataset Build!--------
2025-12-24 15:51:47,690:INFO: --------Get Dataloader!--------
2025-12-24 15:51:47,690:INFO: loading configuration file pretrained_bert_models/chinese_roberta_wwm_large_ext/config.json
2025-12-24 15:51:47,690:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 31,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 21128
}

2025-12-24 15:51:47,690:INFO: loading weights file pretrained_bert_models/chinese_roberta_wwm_large_ext/pytorch_model.bin
2025-12-24 15:51:54,608:INFO: Weights of BertNER not initialized from pretrained model: ['classifier.weight', 'classifier.bias', 'crf.start_transitions', 'crf.end_transitions', 'crf.transitions']
2025-12-24 15:51:54,609:INFO: Weights from pretrained model not used in BertNER: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
2025-12-24 15:51:56,080:INFO: --------Start Training!--------
2025-12-24 15:54:31,013:INFO: Epoch: 1, train loss: 81.86771738824766
2025-12-24 15:54:37,635:INFO: Epoch: 1, dev loss: 54.90143224928114, f1 score: 0.7786967924147671
2025-12-24 15:54:37,637:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 15:54:42,314:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 15:54:42,314:INFO: --------Save best model!--------
2025-12-24 15:54:42,314:INFO: Best val f1: 0.7786967924147671
2025-12-24 15:54:42,314:INFO: Training Finished!
2025-12-24 15:54:42,365:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-24 15:54:42,365:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-24 15:54:42,365:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-24 15:54:42,365:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 15:54:42,365:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2025-12-24 15:54:42,365:INFO: loading file None
2025-12-24 15:54:42,365:INFO: loading file None
2025-12-24 15:54:42,365:INFO: loading file None
2025-12-24 15:54:43,964:INFO: --------Dataset Build!--------
2025-12-24 15:54:43,964:INFO: --------Get Data-loader!--------
2025-12-24 15:54:43,964:INFO: loading configuration file /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 15:54:43,964:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 31,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 21128
}

2025-12-24 15:54:43,965:INFO: loading weights file /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 15:54:50,875:INFO: --------Load model from /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/--------
2025-12-24 15:54:50,876:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-24 15:54:50,877:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-24 15:54:50,877:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-24 15:54:50,877:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 15:54:50,877:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2025-12-24 15:54:50,877:INFO: loading file None
2025-12-24 15:54:50,877:INFO: loading file None
2025-12-24 15:54:50,877:INFO: loading file None
2025-12-24 15:55:00,410:INFO: --------Bad Cases reserved !--------
2025-12-24 15:55:00,484:INFO: test loss: 53.83736916950771, f1 score: 0.7737756714060032
2025-12-24 15:55:00,484:INFO: f1 score of address: 0.625
2025-12-24 15:55:00,484:INFO: f1 score of book: 0.7886435331230284
2025-12-24 15:55:00,484:INFO: f1 score of company: 0.7694300518134715
2025-12-24 15:55:00,484:INFO: f1 score of game: 0.8132911392405063
2025-12-24 15:55:00,484:INFO: f1 score of government: 0.8122605363984674
2025-12-24 15:55:00,484:INFO: f1 score of movie: 0.7162162162162162
2025-12-24 15:55:00,485:INFO: f1 score of name: 0.8742138364779874
2025-12-24 15:55:00,485:INFO: f1 score of organization: 0.7816711590296497
2025-12-24 15:55:00,485:INFO: f1 score of position: 0.7816091954022988
2025-12-24 15:55:00,485:INFO: f1 score of scene: 0.7294117647058823
2025-12-24 16:08:45,606:INFO: device: cuda:0
2025-12-24 16:08:45,606:INFO: --------Process Done!--------
2025-12-24 16:08:45,796:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-24 16:08:45,796:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-24 16:08:45,796:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-24 16:08:45,796:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 16:08:45,796:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2025-12-24 16:08:45,796:INFO: loading file None
2025-12-24 16:08:45,797:INFO: loading file None
2025-12-24 16:08:45,797:INFO: loading file None
2025-12-24 16:08:57,522:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-24 16:08:57,522:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-24 16:08:57,522:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-24 16:08:57,522:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 16:08:57,522:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2025-12-24 16:08:57,522:INFO: loading file None
2025-12-24 16:08:57,522:INFO: loading file None
2025-12-24 16:08:57,522:INFO: loading file None
2025-12-24 16:08:58,825:INFO: --------Dataset Build!--------
2025-12-24 16:08:58,826:INFO: --------Get Dataloader!--------
2025-12-24 16:08:58,826:INFO: loading configuration file pretrained_bert_models/chinese_roberta_wwm_large_ext/config.json
2025-12-24 16:08:58,826:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 31,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 21128
}

2025-12-24 16:08:58,827:INFO: loading weights file pretrained_bert_models/chinese_roberta_wwm_large_ext/pytorch_model.bin
2025-12-24 16:09:05,833:INFO: Weights of BertNER not initialized from pretrained model: ['classifier.weight', 'classifier.bias', 'crf.start_transitions', 'crf.end_transitions', 'crf.transitions']
2025-12-24 16:09:05,833:INFO: Weights from pretrained model not used in BertNER: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
2025-12-24 16:09:07,264:INFO: --------Start Training!--------
2025-12-24 16:10:03,225:INFO: Epoch: 1, train loss: 910.9787588088033
2025-12-24 16:10:07,047:INFO: Epoch: 1, dev loss: 257.03585860308476, f1 score: 0.7136994332616767
2025-12-24 16:10:07,048:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 16:10:11,895:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 16:10:11,895:INFO: --------Save best model!--------
2025-12-24 16:11:06,860:INFO: Epoch: 2, train loss: 231.11358551931852
2025-12-24 16:11:10,696:INFO: Epoch: 2, dev loss: 245.07177689496208, f1 score: 0.738895326380842
2025-12-24 16:11:10,697:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 16:11:15,331:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 16:11:15,331:INFO: --------Save best model!--------
2025-12-24 16:12:10,702:INFO: Epoch: 3, train loss: 162.8708882851176
2025-12-24 16:12:14,523:INFO: Epoch: 3, dev loss: 241.17775142894072, f1 score: 0.7557911268158619
2025-12-24 16:12:14,524:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 16:12:19,139:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 16:12:19,139:INFO: --------Save best model!--------
2025-12-24 16:13:14,612:INFO: Epoch: 4, train loss: 116.74426066836115
2025-12-24 16:13:18,485:INFO: Epoch: 4, dev loss: 273.25470599006206, f1 score: 0.7507082152974504
2025-12-24 16:14:14,063:INFO: Epoch: 5, train loss: 85.58602844842589
2025-12-24 16:14:17,969:INFO: Epoch: 5, dev loss: 327.5203211167279, f1 score: 0.7448680351906158
2025-12-24 16:15:13,708:INFO: Epoch: 6, train loss: 66.87096503858912
2025-12-24 16:15:17,571:INFO: Epoch: 6, dev loss: 294.34602445714614, f1 score: 0.7596618357487923
2025-12-24 16:15:17,572:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 16:15:22,164:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 16:15:22,165:INFO: --------Save best model!--------
2025-12-24 16:16:17,796:INFO: Epoch: 7, train loss: 49.00247767734842
2025-12-24 16:16:21,676:INFO: Epoch: 7, dev loss: 342.18779889275044, f1 score: 0.764116940328394
2025-12-24 16:16:21,677:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 16:16:26,186:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 16:16:26,186:INFO: --------Save best model!--------
2025-12-24 16:17:21,643:INFO: Epoch: 8, train loss: 36.9509970221189
2025-12-24 16:17:25,611:INFO: Epoch: 8, dev loss: 376.3104010189281, f1 score: 0.7753770892784346
2025-12-24 16:17:25,612:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 16:17:30,266:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 16:17:30,267:INFO: --------Save best model!--------
2025-12-24 16:18:25,336:INFO: Epoch: 9, train loss: 27.787132621991752
2025-12-24 16:18:29,206:INFO: Epoch: 9, dev loss: 402.8327246273265, f1 score: 0.7615787354007251
2025-12-24 16:19:24,470:INFO: Epoch: 10, train loss: 24.169318554818435
2025-12-24 16:19:28,333:INFO: Epoch: 10, dev loss: 399.79714113123276, f1 score: 0.7664146438519697
2025-12-24 16:20:23,925:INFO: Epoch: 11, train loss: 22.205402292434137
2025-12-24 16:20:27,793:INFO: Epoch: 11, dev loss: 432.7169413847082, f1 score: 0.7682755858201482
2025-12-24 16:21:22,981:INFO: Epoch: 12, train loss: 17.805190844897783
2025-12-24 16:21:26,878:INFO: Epoch: 12, dev loss: 482.591163186466, f1 score: 0.7782007613704669
2025-12-24 16:21:26,879:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 16:21:31,535:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 16:21:31,535:INFO: --------Save best model!--------
2025-12-24 16:22:26,793:INFO: Epoch: 13, train loss: 15.89643949880065
2025-12-24 16:22:30,652:INFO: Epoch: 13, dev loss: 511.3852269789752, f1 score: 0.7713532156624061
2025-12-24 16:23:25,993:INFO: Epoch: 14, train loss: 15.297879222202615
2025-12-24 16:23:29,842:INFO: Epoch: 14, dev loss: 453.7863307279699, f1 score: 0.772790191813328
2025-12-24 16:24:25,616:INFO: Epoch: 15, train loss: 12.460121859811714
2025-12-24 16:24:29,494:INFO: Epoch: 15, dev loss: 558.4156633264878, f1 score: 0.771225937183384
2025-12-24 16:25:24,816:INFO: Epoch: 16, train loss: 12.954880144729866
2025-12-24 16:25:28,722:INFO: Epoch: 16, dev loss: 579.2881317138672, f1 score: 0.769904458598726
2025-12-24 16:26:24,031:INFO: Epoch: 17, train loss: 14.945884245063606
2025-12-24 16:26:27,880:INFO: Epoch: 17, dev loss: 539.0926154641544, f1 score: 0.7798896382587369
2025-12-24 16:26:27,881:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 16:26:32,264:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 16:26:32,264:INFO: --------Save best model!--------
2025-12-24 16:27:27,549:INFO: Epoch: 18, train loss: 11.76289430624581
2025-12-24 16:27:31,444:INFO: Epoch: 18, dev loss: 558.7040827134076, f1 score: 0.7856418576353681
2025-12-24 16:27:31,445:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 16:27:35,962:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 16:27:35,962:INFO: --------Save best model!--------
2025-12-24 16:28:31,470:INFO: Epoch: 19, train loss: 11.565862712293569
2025-12-24 16:28:35,335:INFO: Epoch: 19, dev loss: 620.0877164952896, f1 score: 0.7799352750809062
2025-12-24 16:29:30,612:INFO: Epoch: 20, train loss: 10.058284803585645
2025-12-24 16:29:34,478:INFO: Epoch: 20, dev loss: 621.7255944644703, f1 score: 0.7827999999999999
2025-12-24 16:30:29,682:INFO: Epoch: 21, train loss: 9.728074725311581
2025-12-24 16:30:33,544:INFO: Epoch: 21, dev loss: 651.5203875373392, f1 score: 0.7834343434343435
2025-12-24 16:31:28,550:INFO: Epoch: 22, train loss: 8.059757622948574
2025-12-24 16:31:32,422:INFO: Epoch: 22, dev loss: 655.7545498118681, f1 score: 0.7864393016646366
2025-12-24 16:31:32,424:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 16:31:37,010:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 16:31:37,010:INFO: --------Save best model!--------
2025-12-24 16:32:32,302:INFO: Epoch: 23, train loss: 7.492900307028994
2025-12-24 16:32:36,197:INFO: Epoch: 23, dev loss: 735.6234979068531, f1 score: 0.7809137055837563
2025-12-24 16:33:31,322:INFO: Epoch: 24, train loss: 6.13329007365916
2025-12-24 16:33:35,180:INFO: Epoch: 24, dev loss: 730.4018680348116, f1 score: 0.7852485737571312
2025-12-24 16:34:30,419:INFO: Epoch: 25, train loss: 5.573230264997325
2025-12-24 16:34:34,279:INFO: Epoch: 25, dev loss: 743.4818644804113, f1 score: 0.7927524429967426
2025-12-24 16:34:34,280:INFO: Configuration saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 16:34:38,859:INFO: Model weights saved in /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 16:34:38,860:INFO: --------Save best model!--------
2025-12-24 16:35:33,850:INFO: Epoch: 26, train loss: 5.180781644563077
2025-12-24 16:35:37,711:INFO: Epoch: 26, dev loss: 747.236749088063, f1 score: 0.787952787952788
2025-12-24 16:36:33,354:INFO: Epoch: 27, train loss: 3.470484426706144
2025-12-24 16:36:37,202:INFO: Epoch: 27, dev loss: 771.6235580444336, f1 score: 0.7859308671922378
2025-12-24 16:37:32,255:INFO: Epoch: 28, train loss: 3.232016749507917
2025-12-24 16:37:36,121:INFO: Epoch: 28, dev loss: 768.7040611715878, f1 score: 0.7867182725606029
2025-12-24 16:38:31,212:INFO: Epoch: 29, train loss: 3.686768084862838
2025-12-24 16:38:35,073:INFO: Epoch: 29, dev loss: 793.5112627814798, f1 score: 0.7874847622917514
2025-12-24 16:39:30,256:INFO: Epoch: 30, train loss: 6.053338322210626
2025-12-24 16:39:34,097:INFO: Epoch: 30, dev loss: 757.405683629653, f1 score: 0.7859875176162673
2025-12-24 16:40:29,490:INFO: Epoch: 31, train loss: 3.532836798689153
2025-12-24 16:40:33,379:INFO: Epoch: 31, dev loss: 784.5919027889477, f1 score: 0.7888413765017308
2025-12-24 16:41:28,654:INFO: Epoch: 32, train loss: 2.5532821337185285
2025-12-24 16:41:32,533:INFO: Epoch: 32, dev loss: 783.1309850356158, f1 score: 0.7893776606527468
2025-12-24 16:42:27,881:INFO: Epoch: 33, train loss: 1.5504399911798659
2025-12-24 16:42:31,733:INFO: Epoch: 33, dev loss: 793.4152764713062, f1 score: 0.7900933820544052
2025-12-24 16:43:27,129:INFO: Epoch: 34, train loss: 1.060332700757697
2025-12-24 16:43:30,994:INFO: Epoch: 34, dev loss: 793.0752177518957, f1 score: 0.7877072381722604
2025-12-24 16:44:26,385:INFO: Epoch: 35, train loss: 0.8618661991440424
2025-12-24 16:44:30,251:INFO: Epoch: 35, dev loss: 770.1698087804458, f1 score: 0.7882472137791287
2025-12-24 16:44:30,252:INFO: Best val f1: 0.7927524429967426
2025-12-24 16:44:30,252:INFO: Training Finished!
2025-12-24 16:44:30,297:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-24 16:44:30,297:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-24 16:44:30,297:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-24 16:44:30,297:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 16:44:30,297:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2025-12-24 16:44:30,297:INFO: loading file None
2025-12-24 16:44:30,297:INFO: loading file None
2025-12-24 16:44:30,297:INFO: loading file None
2025-12-24 16:44:31,885:INFO: --------Dataset Build!--------
2025-12-24 16:44:31,886:INFO: --------Get Data-loader!--------
2025-12-24 16:44:31,886:INFO: loading configuration file /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/config.json
2025-12-24 16:44:31,886:INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 31,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 21128
}

2025-12-24 16:44:31,886:INFO: loading weights file /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/pytorch_model.bin
2025-12-24 16:44:38,638:INFO: --------Load model from /home/c403/msy/CLUENER2020/BERT-CRF/experiments/clue/--------
2025-12-24 16:44:38,640:INFO: Model name 'pretrained_bert_models/bert-base-chinese/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming 'pretrained_bert_models/bert-base-chinese/' is a path or url to a directory containing tokenizer files.
2025-12-24 16:44:38,640:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/added_tokens.json. We won't load it.
2025-12-24 16:44:38,640:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/special_tokens_map.json. We won't load it.
2025-12-24 16:44:38,640:INFO: Didn't find file pretrained_bert_models/bert-base-chinese/tokenizer_config.json. We won't load it.
2025-12-24 16:44:38,640:INFO: loading file pretrained_bert_models/bert-base-chinese/vocab.txt
2025-12-24 16:44:38,641:INFO: loading file None
2025-12-24 16:44:38,641:INFO: loading file None
2025-12-24 16:44:38,641:INFO: loading file None
2025-12-24 16:44:44,938:INFO: --------Bad Cases reserved !--------
2025-12-24 16:44:45,011:INFO: test loss: 749.5836450485956, f1 score: 0.7905935050391937
2025-12-24 16:44:45,011:INFO: f1 score of address: 0.6174496644295303
2025-12-24 16:44:45,011:INFO: f1 score of book: 0.8090614886731392
2025-12-24 16:44:45,011:INFO: f1 score of company: 0.8082368082368083
2025-12-24 16:44:45,011:INFO: f1 score of game: 0.8503184713375798
2025-12-24 16:44:45,011:INFO: f1 score of government: 0.806083650190114
2025-12-24 16:44:45,011:INFO: f1 score of movie: 0.8210526315789474
2025-12-24 16:44:45,011:INFO: f1 score of name: 0.880927291886196
2025-12-24 16:44:45,011:INFO: f1 score of organization: 0.7891891891891892
2025-12-24 16:44:45,011:INFO: f1 score of position: 0.7840000000000001
2025-12-24 16:44:45,011:INFO: f1 score of scene: 0.7338129496402878
